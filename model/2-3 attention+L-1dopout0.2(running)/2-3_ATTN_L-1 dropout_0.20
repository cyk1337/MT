vocab size, en=3713, fr=3949
--------------------------------------------------
Training progress will be logged in:
	model/train_10000sen_2-3layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.20.log
--------------------------------------------------
Trained model will be saved as:
	model/seq2seq_10000sen_2-3layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.20.model
--------------------------------------------------
Existing model not found!
--------------------------------------------------
epoch=1, iter=10000, loss=6.256289, mean loss=6.018733: 100%|███████████████████████████████████████████████| 10000/10000 [28:14<00:00,  5.96it/s]
--------------------------------------------------
precision  | 0.2065
recall     | 0.1966
f1         | 0.2014
--------------------------------------------------
computing perplexity
loss=5.621424: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.13it/s]
--------------------------------------------------
dev perplexity | 47.8749
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 26.26it/s]
BLEU: 5.086
finished computing bleu ... 
--------------------------------------------------
epoch=2, iter=20000, loss=6.145609, mean loss=5.649306: 100%|███████████████████████████████████████████████| 10000/10000 [28:13<00:00,  6.06it/s]
--------------------------------------------------
precision  | 0.2251
recall     | 0.2225
f1         | 0.2238
--------------------------------------------------
computing perplexity
loss=5.903734: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.31it/s]
--------------------------------------------------
dev perplexity | 42.1914
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=3, iter=30000, loss=6.015777, mean loss=5.514452: 100%|███████████████████████████████████████████████| 10000/10000 [28:15<00:00,  6.16it/s]
--------------------------------------------------
precision  | 0.2275
recall     | 0.2267
f1         | 0.2271
--------------------------------------------------
computing perplexity
loss=6.027451: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.22it/s]
--------------------------------------------------
dev perplexity | 39.6710
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:18<00:00, 26.92it/s]
BLEU: 8.477
finished computing bleu ... 
--------------------------------------------------
epoch=4, iter=40000, loss=6.124244, mean loss=5.415101: 100%|███████████████████████████████████████████████| 10000/10000 [27:46<00:00,  5.87it/s]
--------------------------------------------------
precision  | 0.2319
recall     | 0.2306
f1         | 0.2312
--------------------------------------------------
computing perplexity
loss=6.109332: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.18it/s]
--------------------------------------------------
dev perplexity | 37.8538
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=5, iter=50000, loss=6.104076, mean loss=5.328488: 100%|███████████████████████████████████████████████| 10000/10000 [27:53<00:00,  5.86it/s]
--------------------------------------------------
precision  | 0.2366
recall     | 0.2416
f1         | 0.2391
--------------------------------------------------
computing perplexity
loss=6.183603: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.58it/s]
--------------------------------------------------
dev perplexity | 36.5445
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:18<00:00, 26.47it/s]
BLEU: 10.242
finished computing bleu ... 
--------------------------------------------------
epoch=6, iter=60000, loss=6.048268, mean loss=5.248627: 100%|███████████████████████████████████████████████| 10000/10000 [28:03<00:00,  6.02it/s]
--------------------------------------------------
precision  | 0.2428
recall     | 0.2475
f1         | 0.2451
--------------------------------------------------
computing perplexity
loss=6.126746: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.06it/s]
--------------------------------------------------
dev perplexity | 35.6220
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=7, iter=70000, loss=6.146359, mean loss=5.174603: 100%|███████████████████████████████████████████████| 10000/10000 [27:55<00:00,  5.93it/s]
--------------------------------------------------
precision  | 0.2415
recall     | 0.2513
f1         | 0.2463
--------------------------------------------------
computing perplexity
loss=6.138067: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.25it/s]
--------------------------------------------------
dev perplexity | 34.6355
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:18<00:00, 26.59it/s]
BLEU: 11.306
finished computing bleu ... 
--------------------------------------------------
epoch=8, iter=80000, loss=6.187532, mean loss=5.106657: 100%|███████████████████████████████████████████████| 10000/10000 [28:01<00:00,  6.17it/s]
--------------------------------------------------
precision  | 0.2416
recall     | 0.2546
f1         | 0.2479
--------------------------------------------------
computing perplexity
loss=6.155811: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.50it/s]
--------------------------------------------------
dev perplexity | 34.0706
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=9, iter=90000, loss=6.086869, mean loss=5.044402: 100%|███████████████████████████████████████████████| 10000/10000 [27:52<00:00,  5.67it/s]
--------------------------------------------------
precision  | 0.2338
recall     | 0.2535
f1         | 0.2432
--------------------------------------------------
computing perplexity
loss=6.131978: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.60it/s]
--------------------------------------------------
dev perplexity | 33.6618
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:20<00:00, 24.88it/s]
BLEU: 12.213
finished computing bleu ... 
--------------------------------------------------
epoch=10, iter=100000, loss=5.967370, mean loss=4.985385: 100%|█████████████████████████████████████████████| 10000/10000 [27:53<00:00,  6.26it/s]
--------------------------------------------------
precision  | 0.2368
recall     | 0.2574
f1         | 0.2467
--------------------------------------------------
computing perplexity
loss=5.947663: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 26.17it/s]
--------------------------------------------------
dev perplexity | 33.2421
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=11, iter=110000, loss=5.898977, mean loss=4.927637: 100%|█████████████████████████████████████████████| 10000/10000 [27:49<00:00,  6.11it/s]
--------------------------------------------------
precision  | 0.2443
recall     | 0.2627
f1         | 0.2531
--------------------------------------------------
computing perplexity
loss=5.875767: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.05it/s]
--------------------------------------------------
dev perplexity | 33.1048
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 28.96it/s]
BLEU: 13.240
finished computing bleu ... 
--------------------------------------------------
epoch=12, iter=120000, loss=6.000917, mean loss=4.875974: 100%|█████████████████████████████████████████████| 10000/10000 [27:43<00:00,  5.94it/s]
--------------------------------------------------
precision  | 0.2466
recall     | 0.2622
f1         | 0.2542
--------------------------------------------------
computing perplexity
loss=5.694060: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:22<00:00, 22.29it/s]
--------------------------------------------------
dev perplexity | 32.8440
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
Training set predictions
English predictions, s=10000, num=5:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | this can &apos;t &apos;t this this . . _EOS                                     
--------------------------------------------------
precision | 0.2222
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i don &apos;t you you you you a a a . . . . _EOS                                
--------------------------------------------------
precision | 0.1333
recall | 0.2000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a a . _EOS                                                              
--------------------------------------------------
precision | 0.5714
recall | 0.5714
--------------------------------------------------
Src | 我々 は ロビン フッド の 伝説 を 良く 知 っ て い る 。                                              
Ref | we are familiar with the legend of robin hood .                                 
Hyp | we is _UNK _UNK _UNK _UNK _UNK . . _EOS                                         
--------------------------------------------------
precision | 0.2000
recall | 0.2000
--------------------------------------------------
Src | トランク に は 鍵 が かけ られ て い ま す か 。                                                  
Ref | is your trunk locked ?                                                          
Hyp | is you you to to to ? ? _EOS                                                    
--------------------------------------------------
precision | 0.2222
recall | 0.4000
sentences matching filter = 5
plot attention 
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
================================================================================
English predictions, s=0, num=3:
--------------------------------------------------
Src | ステーキ は 中位 で 焼 い て くださ い 。                                                       
Ref | i like my steak medium .                                                        
Hyp | please me in in in . _EOS                                                       
--------------------------------------------------
precision | 0.1429
recall | 0.1667
--------------------------------------------------
Src | 彼女 の 美し さ に 関 し て は 、 疑 う 余地 が な い 。                                            
Ref | there is no doubt as to her beauty .                                            
Hyp | her is not not her in . . . _EOS                                                
--------------------------------------------------
precision | 0.3000
recall | 0.3333
--------------------------------------------------
Src | この 近所 の 家 は どれ も とても よく 似 て い る の で 見分け が つ か な い 。                             
Ref | all the houses in this neighborhood look so much alike that i can &apos;t tell them apart .
Hyp | this is is , , , i i i i &apos;t . . . _EOS                                     
--------------------------------------------------
precision | 0.2667
recall | 0.2222
sentences matching filter = 3
--------------------------------------------------
dev set predictions
English predictions, s=10000, num=3:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | this can &apos;t &apos;t this this . . _EOS                                     
--------------------------------------------------
precision | 0.2222
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i don &apos;t you you you you a a a . . . . _EOS                                
--------------------------------------------------
precision | 0.1333
recall | 0.2000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a a . _EOS                                                              
--------------------------------------------------
precision | 0.5714
recall | 0.5714
sentences matching filter = 3
--------------------------------------------------
--------------------------------------------------
--------------------------------------------------
Finished training. Filenames:
model/train_10000sen_2-3layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.20.log
model/seq2seq_10000sen_2-3layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.20.model

