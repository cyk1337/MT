(mtenv) [skyraider]s1718204: python nmt_translate.py
Japanese English dataset configuration
vocab size, en=3713, fr=3949
--------------------------------------------------
Training progress will be logged in:
	model/train_10000sen_2-3layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.log
--------------------------------------------------
Trained model will be saved as:
	model/seq2seq_10000sen_2-3layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.model
--------------------------------------------------
Existing model not found!
--------------------------------------------------
epoch=1, iter=10000, loss=6.546361, mean loss=6.170134: 100%|████████████████████████████████████████████████████| 10000/10000 [24:55<00:00,  6.92it/s]
--------------------------------------------------
precision  | 0.2049
recall     | 0.2133
f1         | 0.2090
--------------------------------------------------
computing perplexity
loss=5.777657: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:21<00:00, 23.61it/s]
--------------------------------------------------
dev perplexity | 52.3452
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:17<00:00, 29.37it/s]
BLEU: 7.940
finished computing bleu ... 
--------------------------------------------------
epoch=2, iter=20000, loss=6.409678, mean loss=5.812888: 100%|████████████████████████████████████████████████████| 10000/10000 [24:40<00:00,  6.76it/s]
--------------------------------------------------
precision  | 0.2061
recall     | 0.2076
f1         | 0.2069
--------------------------------------------------
computing perplexity
loss=5.752909: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 25.18it/s]
--------------------------------------------------
dev perplexity | 49.4199
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=3, iter=30000, loss=6.350142, mean loss=5.752876: 100%|████████████████████████████████████████████████████| 10000/10000 [24:30<00:00,  7.05it/s]
--------------------------------------------------
precision  | 0.2033
recall     | 0.2052
f1         | 0.2043
--------------------------------------------------
computing perplexity
loss=5.703315: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 27.88it/s]
--------------------------------------------------
dev perplexity | 48.0899
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:16<00:00, 30.23it/s]
BLEU: 5.984
finished computing bleu ... 
--------------------------------------------------
epoch=4, iter=40000, loss=6.224419, mean loss=5.710762: 100%|████████████████████████████████████████████████████| 10000/10000 [24:31<00:00,  6.98it/s]
--------------------------------------------------
precision  | 0.2002
recall     | 0.2010
f1         | 0.2006
--------------------------------------------------
computing perplexity
loss=5.734346: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 25.26it/s]
--------------------------------------------------
dev perplexity | 46.8338
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=5, iter=50000, loss=6.022448, mean loss=5.656246: 100%|████████████████████████████████████████████████████| 10000/10000 [24:35<00:00,  6.97it/s]
--------------------------------------------------
precision  | 0.2106
recall     | 0.2159
f1         | 0.2132
--------------------------------------------------
computing perplexity
loss=5.600953: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 25.34it/s]
--------------------------------------------------
dev perplexity | 44.2879
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:16<00:00, 34.79it/s]
BLEU: 6.253
finished computing bleu ... 
--------------------------------------------------
epoch=6, iter=60000, loss=5.967412, mean loss=5.574720: 100%|████████████████████████████████████████████████████| 10000/10000 [24:21<00:00,  7.12it/s]
--------------------------------------------------
precision  | 0.2209
recall     | 0.2243
f1         | 0.2226
--------------------------------------------------
computing perplexity
loss=5.442309: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 30.83it/s]
--------------------------------------------------
dev perplexity | 42.1743
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=7, iter=70000, loss=5.921796, mean loss=5.502464: 100%|████████████████████████████████████████████████████| 10000/10000 [24:28<00:00,  6.87it/s]
--------------------------------------------------
precision  | 0.2145
recall     | 0.2241
f1         | 0.2192
--------------------------------------------------
computing perplexity
loss=5.511907: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:20<00:00, 27.71it/s]
--------------------------------------------------
dev perplexity | 40.7037
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:16<00:00, 30.17it/s]
BLEU: 8.018
finished computing bleu ... 
--------------------------------------------------
epoch=8, iter=80000, loss=5.844704, mean loss=5.436551: 100%|████████████████████████████████████████████████████| 10000/10000 [25:28<00:00,  5.45it/s]
--------------------------------------------------
precision  | 0.2267
recall     | 0.2328
f1         | 0.2297
--------------------------------------------------
computing perplexity
loss=5.479205: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:21<00:00, 23.28it/s]
--------------------------------------------------
dev perplexity | 39.6782
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=9, iter=90000, loss=5.749475, mean loss=5.375590: 100%|████████████████████████████████████████████████████| 10000/10000 [24:45<00:00,  6.60it/s]
--------------------------------------------------
precision  | 0.2257
recall     | 0.2313
f1         | 0.2285
--------------------------------------------------
computing perplexity
loss=5.609154: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 29.56it/s]
--------------------------------------------------
dev perplexity | 38.6981
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:17<00:00, 28.97it/s]
BLEU: 9.619
finished computing bleu ... 
--------------------------------------------------
epoch=10, iter=100000, loss=5.872420, mean loss=5.321044: 100%|██████████████████████████████████████████████████| 10000/10000 [24:45<00:00,  6.75it/s]
--------------------------------------------------
precision  | 0.2251
recall     | 0.2339
f1         | 0.2294
--------------------------------------------------
computing perplexity
loss=5.449174: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:19<00:00, 25.33it/s]
--------------------------------------------------
dev perplexity | 37.9329
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=11, iter=110000, loss=5.671988, mean loss=5.269683: 100%|██████████████████████████████████████████████████| 10000/10000 [24:56<00:00,  6.74it/s]
--------------------------------------------------
precision  | 0.2297
recall     | 0.2394
f1         | 0.2345
--------------------------------------------------
computing perplexity
loss=5.359550: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:20<00:00, 27.75it/s]
--------------------------------------------------
dev perplexity | 37.5155
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:17<00:00, 29.39it/s]
BLEU: 10.421
finished computing bleu ... 
--------------------------------------------------
epoch=12, iter=120000, loss=5.635389, mean loss=5.218500: 100%|██████████████████████████████████████████████████| 10000/10000 [24:45<00:00,  6.46it/s]
--------------------------------------------------
precision  | 0.2285
recall     | 0.2427
f1         | 0.2354
--------------------------------------------------
computing perplexity
loss=5.092793: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:20<00:00, 24.60it/s]
--------------------------------------------------
dev perplexity | 37.0410
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
Training set predictions
English predictions, s=10000, num=5:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | the is is _UNK in . . _EOS                                                      
--------------------------------------------------
precision | 0.2500
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i have to to you you you you to . . . . . . _EOS                                
--------------------------------------------------
precision | 0.1875
recall | 0.3000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a . . _EOS                                                              
--------------------------------------------------
precision | 0.5714
recall | 0.5714
--------------------------------------------------
Src | 我々 は ロビン フッド の 伝説 を 良く 知 っ て い る 。                                              
Ref | we are familiar with the legend of robin hood .                                 
Hyp | i is a in in the _UNK . . _EOS                                                  
--------------------------------------------------
precision | 0.2000
recall | 0.2000
--------------------------------------------------
Src | トランク に は 鍵 が かけ られ て い ま す か 。                                                  
Ref | is your trunk locked ?                                                          
Hyp | how you _UNK _UNK _UNK _UNK ? ? _EOS                                            
--------------------------------------------------
precision | 0.1111
recall | 0.2000
sentences matching filter = 5
plot attention 
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
================================================================================
English predictions, s=0, num=3:
--------------------------------------------------
Src | ステーキ は 中位 で 焼 い て くださ い 。                                                       
Ref | i like my steak medium .                                                        
Hyp | i is a _UNK . . _EOS                                                            
--------------------------------------------------
precision | 0.2857
recall | 0.3333
--------------------------------------------------
Src | 彼女 の 美し さ に 関 し て は 、 疑 う 余地 が な い 。                                            
Ref | there is no doubt as to her beauty .                                            
Hyp | she is not , , , he . . . _EOS                                                  
--------------------------------------------------
precision | 0.1818
recall | 0.2222
--------------------------------------------------
Src | この 近所 の 家 は どれ も とても よく 似 て い る の で 見分け が つ か な い 。                             
Ref | all the houses in this neighborhood look so much alike that i can &apos;t tell them apart .
Hyp | this is is to to to in in . . . . _EOS                                          
--------------------------------------------------
precision | 0.2308
recall | 0.1667
sentences matching filter = 3
--------------------------------------------------
dev set predictions
English predictions, s=10000, num=3:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | the is is _UNK in . . _EOS                                                      
--------------------------------------------------
precision | 0.2500
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i have to to you you you you to . . . . . . _EOS                                
--------------------------------------------------
precision | 0.1875
recall | 0.3000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a . . _EOS                                                              
--------------------------------------------------
precision | 0.5714
recall | 0.5714
sentences matching filter = 3
--------------------------------------------------
--------------------------------------------------
--------------------------------------------------
Finished training. Filenames:
model/train_10000sen_2-3layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.log
model/seq2seq_10000sen_2-3layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.model

