Japanese English dataset configuration
vocab size, en=3713, fr=3949
--------------------------------------------------
Training progress will be logged in:
	model/train_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.log
--------------------------------------------------
Trained model will be saved as:
	model/seq2seq_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.model
--------------------------------------------------
Existing model not found!
--------------------------------------------------
epoch=1, iter=10000, loss=6.032397, mean loss=6.082747: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:56<00:00, 11.15it/s]
--------------------------------------------------
precision  | 0.2388
recall     | 0.2201
f1         | 0.2290
--------------------------------------------------
computing perplexity
loss=6.303951: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 50.82it/s]
--------------------------------------------------
dev perplexity | 48.9086
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:08<00:00, 57.86it/s]
BLEU: 6.369
finished computing bleu ... 
--------------------------------------------------
epoch=2, iter=20000, loss=5.875142, mean loss=5.674415: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:22<00:00, 11.59it/s]
--------------------------------------------------
precision  | 0.2459
recall     | 0.2409
f1         | 0.2434
--------------------------------------------------
computing perplexity
loss=6.089755: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 43.34it/s]
--------------------------------------------------
dev perplexity | 42.0644
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=3, iter=30000, loss=5.911880, mean loss=5.507145: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:26<00:00, 11.54it/s]
--------------------------------------------------
precision  | 0.2382
recall     | 0.2482
f1         | 0.2431
--------------------------------------------------
computing perplexity
loss=6.080395: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 49.41it/s]
--------------------------------------------------
dev perplexity | 39.1743
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:09<00:00, 55.24it/s]
BLEU: 11.059
finished computing bleu ... 
--------------------------------------------------
epoch=4, iter=40000, loss=5.801756, mean loss=5.402810: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:22<00:00, 10.72it/s]
--------------------------------------------------
precision  | 0.2392
recall     | 0.2484
f1         | 0.2437
--------------------------------------------------
computing perplexity
loss=6.030355: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.26it/s]
--------------------------------------------------
dev perplexity | 37.3565
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=5, iter=50000, loss=5.796825, mean loss=5.321624: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:20<00:00, 11.14it/s]
--------------------------------------------------
precision  | 0.2425
recall     | 0.2513
f1         | 0.2468
--------------------------------------------------
computing perplexity
loss=6.196770: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.31it/s]
--------------------------------------------------
dev perplexity | 35.9083
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:08<00:00, 55.80it/s]
BLEU: 11.481
finished computing bleu ... 
--------------------------------------------------
epoch=6, iter=60000, loss=5.834982, mean loss=5.253400: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:22<00:00, 11.60it/s]
--------------------------------------------------
precision  | 0.2354
recall     | 0.2488
f1         | 0.2419
--------------------------------------------------
computing perplexity
loss=6.100800: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 43.78it/s]
--------------------------------------------------
dev perplexity | 34.8356
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=7, iter=70000, loss=5.831471, mean loss=5.192257: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:21<00:00, 11.14it/s]
--------------------------------------------------
precision  | 0.2411
recall     | 0.2557
f1         | 0.2482
--------------------------------------------------
computing perplexity
loss=6.145748: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.07it/s]
--------------------------------------------------
dev perplexity | 34.0136
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:09<00:00, 54.43it/s]
BLEU: 12.534
finished computing bleu ... 
--------------------------------------------------
epoch=8, iter=80000, loss=5.782790, mean loss=5.133090: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:23<00:00, 11.06it/s]
--------------------------------------------------
precision  | 0.2467
recall     | 0.2561
f1         | 0.2513
--------------------------------------------------
computing perplexity
loss=6.013504: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 42.86it/s]
--------------------------------------------------
dev perplexity | 33.1410
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=9, iter=90000, loss=5.715769, mean loss=5.081346: 100%|██████████████████████████████████████████████████████████| 10000/10000 [14:19<00:00, 11.63it/s]
--------------------------------------------------
precision  | 0.2446
recall     | 0.2581
f1         | 0.2511
--------------------------------------------------
computing perplexity
loss=6.039069: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.22it/s]
--------------------------------------------------
dev perplexity | 32.7201
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:09<00:00, 55.06it/s]
BLEU: 13.188
finished computing bleu ... 
--------------------------------------------------
epoch=10, iter=100000, loss=5.795839, mean loss=5.030925: 100%|████████████████████████████████████████████████████████| 10000/10000 [14:22<00:00, 10.77it/s]
--------------------------------------------------
precision  | 0.2419
recall     | 0.2578
f1         | 0.2496
--------------------------------------------------
computing perplexity
loss=6.008452: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.12it/s]
--------------------------------------------------
dev perplexity | 32.2409
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=11, iter=110000, loss=5.780711, mean loss=4.981246: 100%|████████████████████████████████████████████████████████| 10000/10000 [14:16<00:00, 11.68it/s]
--------------------------------------------------
precision  | 0.2428
recall     | 0.2578
f1         | 0.2501
--------------------------------------------------
computing perplexity
loss=5.923088: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.36it/s]
--------------------------------------------------
dev perplexity | 31.6527
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:09<00:00, 54.00it/s]
BLEU: 13.302
finished computing bleu ... 
--------------------------------------------------
epoch=12, iter=120000, loss=5.541528, mean loss=4.937198: 100%|████████████████████████████████████████████████████████| 10000/10000 [14:23<00:00, 10.96it/s]
--------------------------------------------------
precision  | 0.2429
recall     | 0.2629
f1         | 0.2525
--------------------------------------------------
computing perplexity
loss=5.892351: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.05it/s]
--------------------------------------------------
dev perplexity | 31.4847
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
Training set predictions
English predictions, s=10000, num=5:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | i can &apos;t _UNK this . . _EOS                                                
--------------------------------------------------
precision | 0.2500
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i had &apos;t , you , , you i you you . . _EOS                                  
--------------------------------------------------
precision | 0.2857
recall | 0.4000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a of . . _EOS                                                           
--------------------------------------------------
precision | 0.5000
recall | 0.5714
--------------------------------------------------
Src | 我々 は ロビン フッド の 伝説 を 良く 知 っ て い る 。                                              
Ref | we are familiar with the legend of robin hood .                                 
Hyp | we are _UNK _UNK _UNK _UNK . . _EOS                                             
--------------------------------------------------
precision | 0.3333
recall | 0.3000
--------------------------------------------------
Src | トランク に は 鍵 が かけ られ て い ま す か 。                                                  
Ref | is your trunk locked ?                                                          
Hyp | can you you a in in ? ? _EOS                                                    
--------------------------------------------------
precision | 0.1111
recall | 0.2000
sentences matching filter = 5
plot attention 
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
================================================================================
English predictions, s=0, num=3:
--------------------------------------------------
Src | ステーキ は 中位 で 焼 い て くださ い 。                                                       
Ref | i like my steak medium .                                                        
Hyp | the is is in . . _EOS                                                           
--------------------------------------------------
precision | 0.1429
recall | 0.1667
--------------------------------------------------
Src | 彼女 の 美し さ に 関 し て は 、 疑 う 余地 が な い 。                                            
Ref | there is no doubt as to her beauty .                                            
Hyp | i is no her her her her her her . . . _EOS                                      
--------------------------------------------------
precision | 0.3077
recall | 0.4444
--------------------------------------------------
Src | この 近所 の 家 は どれ も とても よく 似 て い る の で 見分け が つ か な い 。                             
Ref | all the houses in this neighborhood look so much alike that i can &apos;t tell them apart .
Hyp | i is &apos;t this this this this this this this . . . _EOS                      
--------------------------------------------------
precision | 0.2857
recall | 0.2222
sentences matching filter = 3
--------------------------------------------------
dev set predictions
English predictions, s=10000, num=3:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | i can &apos;t _UNK this . . _EOS                                                
--------------------------------------------------
precision | 0.2500
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i had &apos;t , you , , you i you you . . _EOS                                  
--------------------------------------------------
precision | 0.2857
recall | 0.4000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a of . . _EOS                                                           
--------------------------------------------------
precision | 0.5000
recall | 0.5714
sentences matching filter = 3
--------------------------------------------------
--------------------------------------------------
--------------------------------------------------
Finished training. Filenames:
model/train_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.log
model/seq2seq_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.model

