(mtenv) [skywarrior]s1718204: python nmt_translate.py 
Japanese English dataset configuration
vocab size, en=3713, fr=3949
--------------------------------------------------
Training progress will be logged in:
	model/train_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.log
--------------------------------------------------
Trained model will be saved as:
	model/seq2seq_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.model
--------------------------------------------------
Existing model not found!
--------------------------------------------------
epoch=1, iter=10000, loss=5.961278, mean loss=6.036258: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [14:09<00:00, 11.69it/s]
--------------------------------------------------
precision  | 0.2588
recall     | 0.2322
f1         | 0.2448
--------------------------------------------------
computing perplexity
loss=5.963062: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.67it/s]
--------------------------------------------------
dev perplexity | 46.7375
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:08<00:00, 56.01it/s]
BLEU: 7.278
finished computing bleu ... 
--------------------------------------------------
epoch=2, iter=20000, loss=5.785944, mean loss=5.584238: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [13:49<00:00, 11.59it/s]
--------------------------------------------------
precision  | 0.2476
recall     | 0.2440
f1         | 0.2458
--------------------------------------------------
computing perplexity
loss=5.725296: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.73it/s]
--------------------------------------------------
dev perplexity | 40.8322
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=3, iter=30000, loss=5.701664, mean loss=5.436953: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [13:48<00:00, 11.64it/s]
--------------------------------------------------
precision  | 0.2442
recall     | 0.2469
f1         | 0.2456
--------------------------------------------------
computing perplexity
loss=5.703876: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 45.44it/s]
--------------------------------------------------
dev perplexity | 38.2132
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:08<00:00, 56.54it/s]
BLEU: 10.788
finished computing bleu ... 
--------------------------------------------------
epoch=4, iter=40000, loss=5.730999, mean loss=5.327971: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [13:48<00:00, 11.13it/s]
--------------------------------------------------
precision  | 0.2524
recall     | 0.2510
f1         | 0.2517
--------------------------------------------------
computing perplexity
loss=5.636513: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 43.25it/s]
--------------------------------------------------
dev perplexity | 36.6516
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=5, iter=50000, loss=5.639073, mean loss=5.235076: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [14:03<00:00, 11.35it/s]
--------------------------------------------------
precision  | 0.2517
recall     | 0.2541
f1         | 0.2529
--------------------------------------------------
computing perplexity
loss=5.428069: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:12<00:00, 40.22it/s]
--------------------------------------------------
dev perplexity | 35.3237
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:09<00:00, 55.55it/s]
BLEU: 11.559
finished computing bleu ... 
--------------------------------------------------
epoch=6, iter=60000, loss=5.570600, mean loss=5.152201: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [13:46<00:00, 11.42it/s]
--------------------------------------------------
precision  | 0.2546
recall     | 0.2552
f1         | 0.2549
--------------------------------------------------
computing perplexity
loss=5.301759: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.30it/s]
--------------------------------------------------
dev perplexity | 34.2639
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=7, iter=70000, loss=5.504144, mean loss=5.076285: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [13:48<00:00, 11.53it/s]
--------------------------------------------------
precision  | 0.2537
recall     | 0.2567
f1         | 0.2552
--------------------------------------------------
computing perplexity
loss=5.216441: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.09it/s]
--------------------------------------------------
dev perplexity | 33.5314
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:08<00:00, 57.37it/s]
BLEU: 12.092
finished computing bleu ... 
--------------------------------------------------
epoch=8, iter=80000, loss=5.447971, mean loss=5.003451: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [13:50<00:00, 11.77it/s]
--------------------------------------------------
precision  | 0.2581
recall     | 0.2561
f1         | 0.2571
--------------------------------------------------
computing perplexity
loss=5.429615: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.95it/s]
--------------------------------------------------
dev perplexity | 32.8816
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=9, iter=90000, loss=5.433649, mean loss=4.934047: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [13:46<00:00, 11.75it/s]
--------------------------------------------------
precision  | 0.2585
recall     | 0.2618
f1         | 0.2601
--------------------------------------------------
computing perplexity
loss=5.392405: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 45.00it/s]
--------------------------------------------------
dev perplexity | 32.5083
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:09<00:00, 52.18it/s]
BLEU: 12.761
finished computing bleu ... 
--------------------------------------------------
epoch=10, iter=100000, loss=5.383402, mean loss=4.865839: 100%|███████████████████████████████████████████████████████████| 10000/10000 [13:48<00:00, 11.71it/s]
--------------------------------------------------
precision  | 0.2553
recall     | 0.2627
f1         | 0.2590
--------------------------------------------------
computing perplexity
loss=5.368737: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 45.21it/s]
--------------------------------------------------
dev perplexity | 32.1455
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=11, iter=110000, loss=5.380394, mean loss=4.800910: 100%|███████████████████████████████████████████████████████████| 10000/10000 [13:54<00:00, 11.51it/s]
--------------------------------------------------
precision  | 0.2576
recall     | 0.2642
f1         | 0.2609
--------------------------------------------------
computing perplexity
loss=5.285242: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 45.02it/s]
--------------------------------------------------
dev perplexity | 31.9926
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:09<00:00, 55.46it/s]
BLEU: 13.442
finished computing bleu ... 
--------------------------------------------------
epoch=12, iter=120000, loss=5.509760, mean loss=4.736935: 100%|███████████████████████████████████████████████████████████| 10000/10000 [14:10<00:00, 11.58it/s]
--------------------------------------------------
precision  | 0.2580
recall     | 0.2693
f1         | 0.2635
--------------------------------------------------
computing perplexity
loss=5.368472: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.97it/s]
--------------------------------------------------
dev perplexity | 31.7241
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
Training set predictions
English predictions, s=10000, num=5:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | i can &apos;t this this this . _EOS                                             
--------------------------------------------------
precision | 0.2500
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i i &apos;t to to to the the the the . . _EOS                                   
--------------------------------------------------
precision | 0.2308
recall | 0.3000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a a . . _EOS                                                            
--------------------------------------------------
precision | 0.5000
recall | 0.5714
--------------------------------------------------
Src | 我々 は ロビン フッド の 伝説 を 良く 知 っ て い る 。                                              
Ref | we are familiar with the legend of robin hood .                                 
Hyp | we are _UNK _UNK for the . . _EOS                                               
--------------------------------------------------
precision | 0.4444
recall | 0.4000
--------------------------------------------------
Src | トランク に は 鍵 が かけ られ て い ま す か 。                                                  
Ref | is your trunk locked ?                                                          
Hyp | are you the in in ? ? _EOS                                                      
--------------------------------------------------
precision | 0.1250
recall | 0.2000
sentences matching filter = 5
plot attention 
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
================================================================================
English predictions, s=0, num=3:
--------------------------------------------------
Src | ステーキ は 中位 で 焼 い て くださ い 。                                                       
Ref | i like my steak medium .                                                        
Hyp | i &apos;m in in in . . _EOS                                                     
--------------------------------------------------
precision | 0.2500
recall | 0.3333
--------------------------------------------------
Src | 彼女 の 美し さ に 関 し て は 、 疑 う 余地 が な い 。                                            
Ref | there is no doubt as to her beauty .                                            
Hyp | her her her her to her her her . . . _EOS                                       
--------------------------------------------------
precision | 0.2500
recall | 0.3333
--------------------------------------------------
Src | この 近所 の 家 は どれ も とても よく 似 て い る の で 見分け が つ か な い 。                             
Ref | all the houses in this neighborhood look so much alike that i can &apos;t tell them apart .
Hyp | i can can this this this this this . . . . . _EOS                               
--------------------------------------------------
precision | 0.2857
recall | 0.2222
sentences matching filter = 3
--------------------------------------------------
dev set predictions
English predictions, s=10000, num=3:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | i can &apos;t this this this . _EOS                                             
--------------------------------------------------
precision | 0.2500
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i i &apos;t to to to the the the the . . _EOS                                   
--------------------------------------------------
precision | 0.2308
recall | 0.3000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a a a . . _EOS                                                            
--------------------------------------------------
precision | 0.5000
recall | 0.5714
sentences matching filter = 3
--------------------------------------------------
--------------------------------------------------
--------------------------------------------------
Finished training. Filenames:
model/train_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.log
model/seq2seq_10000sen_1-1layers_100units_ja_en_exp1_NO_ATTN_dropout_0.20.model

