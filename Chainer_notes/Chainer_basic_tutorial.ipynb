{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Chain: **define-by-run** scheme\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([5], dtype=np.float32)\n",
    "x= Variable(x_data)\n",
    "\n",
    "y= x**2 - 2*x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is also Variable\n",
    "y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# error propagation\n",
    "y.backward()\n",
    "# gradient is computed and stored in `grad`\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 2*x\n",
    "y = x**2 - z + 1\n",
    "# set return_grad = True\n",
    "y.backward(retain_grad=True)\n",
    "z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 2*x\n",
    "y = x**2 - z + 1\n",
    "# did no set return_grad, no \n",
    "y.backward()\n",
    "z.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   2.,   4.],\n",
       "       [  6.,   8.,  10.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32))\n",
    "y = x**2 - 2*x + 1\n",
    "y.grad = np.ones((2, 3), dtype=np.float32)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "links\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f.W.data.shape (2, 3)\n",
      "f.b.data: [ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#from 3dim to 2dim\n",
    "# f = x.dot(W.T) + b\n",
    "f = L.Linear(3,2)\n",
    "print('f.W.data.shape', f.W.data.shape)\n",
    "print(\"f.b.data:\", f.b.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.24425924,  -3.89838886],\n",
       "       [  1.06489491, -10.12237167]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32))\n",
    "y = f(x)\n",
    "y.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example MINIST\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "train, test = datasets.get_mnist()\n",
    "train_iter = iterators.SerialIterator(train, batch_size=100, shuffle=True)\n",
    "# repeat=False, which means we stop iteration when all examples are visited. This option is usually required for the test/validation datasets\n",
    "test_iter = iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
    "            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "            self.l3 = L.Linear(None, n_out)    # n_units -> n_out\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        y = self.l3(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = L.Classifier(MLP(100, 10))  # the input size, 784, is inferred\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = training.StandardUpdater(train_iter, optimizer)\n",
    "trainer = training.Trainer(updater, (20, 'epoch'), out='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy']))\n",
    "trainer.extend(extensions.ProgressBar())\n",
    "trainer.run()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "import numpy as np\n",
    "\n",
    "import chainer.links as L\n",
    "from chainer import Variable, Chain, optimizers\n",
    "\n",
    "\n",
    "l = L.LSTM(100, 50)\n",
    "l.reset_state()\n",
    "x = Variable(np.random.rand(10, 100).astype(np.float32))\n",
    "y = l(x)\n",
    "\n",
    "\n",
    "class RNN(Chain):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.embed = L.EmbedID(1000, 100) # word embedding\n",
    "            self.mid = L.LSTM(100, 50) # 1st LSTM layer\n",
    "            self.out = L.Linear(50, 1000) # deef-forward output layer\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mid.reset_state()\n",
    "\n",
    "    def __call__(self,cur_word):\n",
    "        # Given the current word ID, predict the next word\n",
    "        x = self.embed(cur_word)\n",
    "        h = self.mid(x)\n",
    "        y = self.mid(h)\n",
    "        return y\n",
    "\n",
    "rnn = RNN()\n",
    "model = L.Classifier(rnn)\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
