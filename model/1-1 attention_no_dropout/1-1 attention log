Japanese English dataset configuration
vocab size, en=3713, fr=3949
--------------------------------------------------
Training progress will be logged in:
	model/train_10000sen_1-1layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.00.log
--------------------------------------------------
Trained model will be saved as:
	model/seq2seq_10000sen_1-1layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.00.model
--------------------------------------------------
Existing model not found!
--------------------------------------------------
epoch=1, iter=10000, loss=6.101300, mean loss=5.947701: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [17:51<00:00,  9.33it/s]
--------------------------------------------------
precision  | 0.2588
recall     | 0.2339
f1         | 0.2457
--------------------------------------------------
computing perplexity
loss=5.845852: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 41.85it/s]
--------------------------------------------------
dev perplexity | 45.2071
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:10<00:00, 48.00it/s]
BLEU: 7.339
finished computing bleu ... 
--------------------------------------------------
epoch=2, iter=20000, loss=5.970627, mean loss=5.560594: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [17:51<00:00,  9.33it/s]
--------------------------------------------------
precision  | 0.2538
recall     | 0.2416
f1         | 0.2476
--------------------------------------------------
computing perplexity
loss=6.066050: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 41.55it/s]
--------------------------------------------------
dev perplexity | 41.1636
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=3, iter=30000, loss=5.832138, mean loss=5.409770: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [18:20<00:00,  9.09it/s]
--------------------------------------------------
precision  | 0.2449
recall     | 0.2427
f1         | 0.2438
--------------------------------------------------
computing perplexity
loss=5.898487: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 40.81it/s]
--------------------------------------------------
dev perplexity | 38.4966
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:10<00:00, 45.94it/s]
BLEU: 9.958
finished computing bleu ... 
--------------------------------------------------
epoch=4, iter=40000, loss=5.773894, mean loss=5.292495: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [17:58<00:00,  9.27it/s]
--------------------------------------------------
precision  | 0.2497
recall     | 0.2546
f1         | 0.2521
--------------------------------------------------
computing perplexity
loss=5.687515: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 36.42it/s]
--------------------------------------------------
dev perplexity | 36.5161
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=5, iter=50000, loss=5.719168, mean loss=5.194875: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [17:52<00:00,  9.33it/s]
--------------------------------------------------
precision  | 0.2461
recall     | 0.2563
f1         | 0.2511
--------------------------------------------------
computing perplexity
loss=5.735422: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 36.18it/s]
--------------------------------------------------
dev perplexity | 35.4561
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 45.02it/s]
BLEU: 12.623
finished computing bleu ... 
--------------------------------------------------
epoch=6, iter=60000, loss=5.711620, mean loss=5.107991: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [17:51<00:00,  9.33it/s]
--------------------------------------------------
precision  | 0.2488
recall     | 0.2600
f1         | 0.2543
--------------------------------------------------
computing perplexity
loss=5.727042: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 36.40it/s]
--------------------------------------------------
dev perplexity | 34.6763
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=7, iter=70000, loss=5.639012, mean loss=5.025921: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [17:58<00:00,  9.27it/s]
--------------------------------------------------
precision  | 0.2533
recall     | 0.2657
f1         | 0.2594
--------------------------------------------------
computing perplexity
loss=5.704185: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 36.20it/s]
--------------------------------------------------
dev perplexity | 34.1057
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 45.10it/s]
BLEU: 13.809
finished computing bleu ... 
--------------------------------------------------
epoch=8, iter=80000, loss=5.572856, mean loss=4.948007: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [18:09<00:00,  9.18it/s]
--------------------------------------------------
precision  | 0.2588
recall     | 0.2741
f1         | 0.2662
--------------------------------------------------
computing perplexity
loss=5.660533: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 35.90it/s]
--------------------------------------------------
dev perplexity | 33.7300
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=9, iter=90000, loss=5.434934, mean loss=4.871784: 100%|█████████████████████████████████████████████████████████████| 10000/10000 [18:17<00:00,  9.11it/s]
--------------------------------------------------
precision  | 0.2580
recall     | 0.2734
f1         | 0.2655
--------------------------------------------------
computing perplexity
loss=5.901274: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 36.45it/s]
--------------------------------------------------
dev perplexity | 33.5122
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.62it/s]
BLEU: 14.474
finished computing bleu ... 
--------------------------------------------------
epoch=10, iter=100000, loss=5.369211, mean loss=4.798238: 100%|███████████████████████████████████████████████████████████| 10000/10000 [18:08<00:00,  9.19it/s]
--------------------------------------------------
precision  | 0.2598
recall     | 0.2750
f1         | 0.2672
--------------------------------------------------
computing perplexity
loss=5.790816: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:14<00:00, 35.69it/s]
--------------------------------------------------
dev perplexity | 33.5418
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
epoch=11, iter=110000, loss=5.233528, mean loss=4.727315: 100%|███████████████████████████████████████████████████████████| 10000/10000 [18:11<00:00,  9.16it/s]
--------------------------------------------------
precision  | 0.2641
recall     | 0.2802
f1         | 0.2719
--------------------------------------------------
computing perplexity
loss=5.501932: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 36.35it/s]
--------------------------------------------------
dev perplexity | 33.4973
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
computing bleu
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 44.15it/s]
BLEU: 15.346
finished computing bleu ... 
--------------------------------------------------
epoch=12, iter=120000, loss=5.152323, mean loss=4.659872: 100%|███████████████████████████████████████████████████████████| 10000/10000 [17:52<00:00,  9.32it/s]
--------------------------------------------------
precision  | 0.2620
recall     | 0.2780
f1         | 0.2698
--------------------------------------------------
computing perplexity
loss=5.670335: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 36.14it/s]
--------------------------------------------------
dev perplexity | 33.5248
# words in dev | 4557
--------------------------------------------------
Saving model
Finished saving model
--------------------------------------------------
Training set predictions
English predictions, s=10000, num=5:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | this cannot can &apos;t this this . . _EOS                                      
--------------------------------------------------
precision | 0.2222
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i you you you you _UNK you the you you you . . . _EOS                           
--------------------------------------------------
precision | 0.1333
recall | 0.2000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a of his . . _EOS                                                         
--------------------------------------------------
precision | 0.5000
recall | 0.5714
--------------------------------------------------
Src | 我々 は ロビン フッド の 伝説 を 良く 知 っ て い る 。                                              
Ref | we are familiar with the legend of robin hood .                                 
Hyp | we are _UNK _UNK _UNK _UNK _UNK . . _EOS                                        
--------------------------------------------------
precision | 0.3000
recall | 0.3000
--------------------------------------------------
Src | トランク に は 鍵 が かけ られ て い ま す か 。                                                  
Ref | is your trunk locked ?                                                          
Hyp | is are in in in in ? _EOS                                                       
--------------------------------------------------
precision | 0.2500
recall | 0.4000
sentences matching filter = 5
plot attention 
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
================================================================================
English predictions, s=0, num=3:
--------------------------------------------------
Src | ステーキ は 中位 で 焼 い て くださ い 。                                                       
Ref | i like my steak medium .                                                        
Hyp | please the , in _UNK . . _EOS                                                   
--------------------------------------------------
precision | 0.1250
recall | 0.1667
--------------------------------------------------
Src | 彼女 の 美し さ に 関 し て は 、 疑 う 余地 が な い 。                                            
Ref | there is no doubt as to her beauty .                                            
Hyp | her don &apos;t not , her her her . _EOS                                        
--------------------------------------------------
precision | 0.2000
recall | 0.2222
--------------------------------------------------
Src | この 近所 の 家 は どれ も とても よく 似 て い る の で 見分け が つ か な い 。                             
Ref | all the houses in this neighborhood look so much alike that i can &apos;t tell them apart .
Hyp | i can can you the , , you you this this this _EOS                               
--------------------------------------------------
precision | 0.3077
recall | 0.2222
sentences matching filter = 3
--------------------------------------------------
dev set predictions
English predictions, s=10000, num=3:
--------------------------------------------------
Src | この 路地 は 通り抜け でき ま せ ん 。                                                         
Ref | this is a dead @-@ end alley .                                                  
Hyp | this cannot can &apos;t this this . . _EOS                                      
--------------------------------------------------
precision | 0.2222
recall | 0.2500
--------------------------------------------------
Src | ええ 、 届 い た の を お 知 らせ する の を 忘れ て しま っ て す み ま せ ん 。                            
Ref | yes , sorry , i forgot to acknowledge it .                                      
Hyp | i you you you you _UNK you the you you you . . . _EOS                           
--------------------------------------------------
precision | 0.1333
recall | 0.2000
--------------------------------------------------
Src | 彼 は ドイツ 生まれ の 人 だ 。                                                             
Ref | he is a german by origin .                                                      
Hyp | he is a of his . . _EOS                                                         
--------------------------------------------------
precision | 0.5000
recall | 0.5714
sentences matching filter = 3
--------------------------------------------------
--------------------------------------------------
--------------------------------------------------
Finished training. Filenames:
model/train_10000sen_1-1layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.00.log
model/seq2seq_10000sen_1-1layers_100units_ja_en_exp1_SOFT_ATTN_dropout_0.00.model

